## 1、基础知识

### 1.1 H264框架

![](https://github.com/Qiaomumer/Images/blob/master/H264原理.png?raw=true)

H.264编码框架分两层：
**VCL**(Video Coding Layer)：负责高效的视频内容表示；
**NAL**(Network Abstraction Layer)：负责以网络所要求的恰当的方式对数据进行打包和传送；



### 1.1 IDR(I帧)、SPS、PPS、SES、P/B帧

1. IDR(Instantaneous Decoding Refresh)：即时解码刷新。一个序列的第一个图像叫做IDR 图像（立即刷新图像），IDR 图像都是I 帧图像(关键帧)。H.264引入 IDR 图像是为了**解码的重同步，当解码器解码到IDR 图像时，立即将参考帧队列清空，将已解码的数据全部输出或抛弃，重新查找参数集，开始一个新的序列**。这样，如果前一个序列出现重大错误，在这里可以获得重新同步的机会。IDR图像之后的图像永远不会使用IDR之前的图像的数据来解码。
2. SPS(Sequence Parameter Sets)：序列参数集，作用于一系列连续的编码图像。
3. PPS(Picture Parameter Set)：图像参数集，作用于编码视频序列中一个或多个独立的图像。
4. SEI(Supplemental Enhancement Information)：附加增强信息，包含了视频画面定时等信息，一般放在主编码图像数据之前，在某些应用中，它可以被省略掉。
5. P帧：前向预测编码帧。P帧表示的是这一帧跟之前的一个关键帧（或P帧）的差别，P帧是I帧后面相隔1~2帧的编码帧，其没有完整画面数据，只有与前一帧的、画面差别的数据。
6. B帧：双向预测内插编码帧。B帧记录的是本帧与前后帧的差别，它是由前面的I或P帧和后面的P帧来进行预测的。
7. x264：H.264是需要付费的编码格式，而x264是符合H.264标准的一个开源项目，是免费的，也就是H264的一个简化版，不支持某些高级特性。但x264非常优秀，并不比H264的商业编码器差。H264采用的核心算法是帧内压缩和帧间压缩，帧内压缩是生成I帧的算法，帧间压缩是生成B帧和P帧的算法。



### 1.2 H.264数据组织形式

数据的组织形式从大到小排序是：`序列(sequence)`、`图像(frame/field-picture)`、`片组(slicegroup)`、`片(slice)`、`宏块(macroblock)`、`块(block)`、`子块(sub-block)`、`像素(pixel)`。

在H.264码流中图像是以`序列`为单位进行组织的，一个序列是由多帧图像被编码后的数据流，以I帧开始，到下一个I帧结束；一帧图像可以分成一个或多个片(slice)，片由宏块组成，**宏块是编码处理的基本单位**，当片编码之后会被打包进一个NALU，也就是**一帧图像对应于一个NALU**。NALU是H.264编码数据存储或传输的基本单位，它除了容纳片还可以容纳其他数据，如SPS、PPS、SEI等。

**一个序列是一段内容差异不太大的图像编码生成的一串数据流**。当运动变化比较少时，一个序列可以很长，这是由于运动变化少就代表图像画面的内容变动就很小，所有就可以编一个I帧，然后后面一直P帧、B帧；当运动变化较大，可能这个序列就比较短，因为图像画面的内容变动大，所以P帧、B帧就相对减少。**一个序列总是以I帧为开始，到下一个I帧结束**，序列包含的图像帧的数量与画面变化情况有关。

![](https://github.com/Qiaomumer/Images/blob/master/H.264数据组织形式.png?raw=true)

### 1.3 H.264中的NAL、NALU

NAL（Network Abstract Layer）是H.264/AVC编码框架中的网络抽象层，它主要负责格式化数据并提供头信息，以保证数据适合各种信道和存储介质上的有效传输。

![](https://github.com/Qiaomumer/Images/blob/master/H264码流_MALU序列.png?raw=true)

NALU(Network Abstract Layer Unit)：是在NAL层中，是H.264编码存储或传输的基本单位，**在H.264码流中每一帧数据就是一个NALU(注：SPS、PPS、SEI不属于帧)**。每个NALU都包含一个头结构，这个头结构占1个字节(8位)，它标明了该NAL单元的是否可丢弃、重要性指示和NALU类型，结构如下：

![](https://github.com/Qiaomumer/Images/blob/master/NALU头结构.png?raw=true)

其中，

**禁止位：**当网络发现NALU存在错误时，该位将被设置为1以方便接收方丢弃该NALU；

**重要性指示**：用于标志该NALU用于重建时的重要性，其值越大表示越重要；

**NALU类型**：用于判断该NALU是否为PPS、SPS、I(关键)/P/B帧等，**一般H.264码流最开始的两个NALU是SPS和PPS，第三个NALU是IDR(I帧)。**

相关值与NALU类型的映射关系图如下：

![](https://github.com/Qiaomumer/Images/blob/master/相关值_NALU类型映射关系图.png?raw=true)

### 1.4 H.264中SPS、PPS、I/P/B帧检测与解析

**H.264码流分层结构：**

H.264码流实际是由多个NALU组成的码流序列集合(如第一层所示)，而一个序列是以I帧开始，以下一个I帧结束。NALU是H.264编码存储或传输的基本单元，NALU由**NALU头部**和**NALU主体**组成(如第二层所示)，其中，NALU头部占1个字节，H.264中的**SPS、PPS、I/P/B帧的检测**正是**通过NALU头部**中的**NALU类型**来实现的。

![](https://github.com/Qiaomumer/Images/blob/master/H.264码流分层结构.png?raw=true)

**H.264文件解析：**

一般来说，编码器编出的首帧数据为SPS与PPS，接着为I帧(关键帧)，再后面就是P帧、B帧…。

对于H.264码流而言，每帧图像的界定符为`0x00000001`(4字节，NALU 对应的Slice 为一帧的开始)、`0x000001`(3字节，不是一帧的开始)，即起始码，其后的一个字节便是NALU头，通过NALU头部中的NALU类型，我们就可以找到所需的SPS、PPS、I/P/B帧。

**SPS、PPS、I/P/B帧检测：**

假设：第一帧数据NALU头为0x67，我们截取码流中的前几帧数据进行分析：

```
第一帧：0000 00 01 67 42 80 1F DA 02 D0 28 68 ….（占17个字节）
第二帧：0000 00 01 68 CE 06 E2 (占8个字节)
第三帧：0000 00 01 65 B8 40 F7 8F FC EB 04 …. (占31872个字节)
第四帧：0000 00 01 41 E2 01 10 EA 4E 9F … (占3408字节)
第五帧：0000 00 01 41 E4 01 10 EC 7B DF 13 … (占2096个字节)
```

NALU类型在NALU头的后五位（即字节下标的3-7位），我们只需要得到这五位的十进制值，再与NAL类型对照表进行比较就可以知道该帧图像是否为SPS、PPS或I帧(关键帧)等。

实际编码过程中，可以将每帧数据起始码的下一个字节与0x1F（==00011111）**相与**取得NAL头的后五位即可得到该帧的类型，比如：

```
0x67& 0x1F = (0110 0111) & (0001 1111) =(0000 0111)=7(十进制)–> SPS
0x68& 0x1F = (0110 1000) & (0001 1111) =(0010 1000)=8(十进制)–> PPS
0x65& 0x1F = (0110 0101) & (0001 1111) =(0000 0101)=5(十进制)–> 关键帧(I帧)
0x41 & 0x1F = (01000001) & (0001 1111) =(0000 0001)=1(十进制) –> 非关键帧(I帧)
```



### 1.5 YUV RGB



YUV传输彩色，兼容黑白（扔掉UV，只用Y），占用频宽少。

因为人眼睛对亮度敏感，对色度不敏感，所以，UV可以少传，所以有了YUV444,YUV422,YUV420等格式。

![](http://blog.chinaunix.net/attachment/201202/3/24439730_13282389538k8V.jpg)

```
I420: YYYYYYYY UU VV    =>YUV420P

YV12: YYYYYYYY VV UU    =>YUV420P

NV12: YYYYYYYY UVUV     =>YUV420SP

NV21: YYYYYYYY VUVU     =>YUV420SP
```



##2、FFmpeg

直播的数据，其实是一组图片，包括I帧、P帧、B帧，当用户第一次观看的时候，会寻找I帧，而播放器会到服务器寻找到最近的I帧反馈给用户。因此，GOP Cache增加了端到端延迟，因为它必须要拿到最近的I帧

![](https://github.com/Qiaomumer/Images/blob/master/FFmpeg%E8%A7%86%E9%A2%91%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.jpg?raw=true)

上图显示了一个完整的视频处理流程。
按照蓝色箭头指向的顺序，从外部协议接收下来的数据依次经过解协议，解封装，解码，像素转换，编码，封装，发送这几个步骤。

这些步骤按照处理数据类型的不同，可以分成几个层次：

    协议层（Protocol Layer）：该层处理的数据为符合特定流媒体协议规范的数据，例如http，rtmp，file等。
    封装层（Format Layer）：该层处理的数据为符合特定封装格式规范的数据，例如mkv，mp4，flv，mpegts，avi等。
    编码层（Codec Layer）：该层处理的数据为符合特定编码标准规范的数据，例如h264，h265，mpeg2，mpeg4等。
    像素层（Pixel Layer）：该层处理的数据为符合特定像素格式规范的数据，例如yuv420p，yuv422p，yuv444p，rgb24等。

## 2、视频编码解码

### 2.1 视频编码框架 
1. `FFmpeg`:是一个跨平台的开源视频框架,能实现视频编码,解码,转码,串流,播放等丰富的功能。其支持的视频格式以及播放协议非常丰富,几乎包含了所有音视频编解码、封装格式以及播放协议。

        Libswresample:  可以对音频进行重采样,rematrixing 以及转换采样格式等操 作。

        Libavcodec:     提供了一个通用的编解码框架,包含了许多视频,音频,字幕流 等编码/解码器。

        Libavformat:    用于对视频进行封装/解封装。

        Libavutil:      包含一些共用的函数,如随机数生成,数据结构,数学运算等。

        Libpostproc:    用于进行视频的一些后期处理。

        Libswscale:     用于视频图像缩放,颜色空间转换等。

        Libavfilter:    提供滤镜功能。
    ​    

2. `X264`:把视频原数据YUV编码压缩成H.264格式
3. `VideoToolbox`:苹果自带的视频硬解码和硬编码API，但是在iOS8之后才开放。
4. `AudioToolbox`:苹果自带的音频硬解码和硬编码API

### 2.2 视频编码技术 



1. `视频压缩编码标准`：对视频进行压缩(视频编码)或者解压缩（视频解码）的编码技术,比如MPEG，H.264,这些视频编码技术是压缩编码视频的

    `主要作用`:是将视频像素数据压缩成为视频码流，从而降低视频的数据量。如果视频不经过压缩编码的话，体积通常是非常大的，一部电影可能就要上百G的空间。

    `注意`:最影响视频质量的是其视频编码数据和音频编码数据，跟封装格式没有多大关系

    `MPEG`:一种视频压缩方式，它采用了帧间压缩，仅存储连续帧之间有差别的地方 ，从而达到较大的压缩比

    `H.264/AVC`:一种视频压缩方式,采用事先预测和与MPEG中的P-B帧一样的帧预测方法压缩，它可以根据需要产生适合网络情况传输的视频流,还有更高的压缩比，有更好的图象质量

        注意：
        1:如果是从单个画面清晰度比较，MPEG4有优势；从动作连贯性上的清晰度，H.264有优势
        2:由于264的算法更加复杂，程序实现烦琐，运行它需要更多的处理器和内存资源。因此，运行264对系统要求是比较高的。
        3:由于264的实现更加灵活，它把一些实现留给了厂商自己去实现，虽然这样给实现带来了很多好处;
          但是不同产品之间互通成了很大的问题，造成了通过A公司的编码器编出的数据，必须通过A公司的解码器去解这样尴尬的事情



2. `H.265/HEVC`:一种视频压缩方式,基于H.264，保留原来的某些技术，同时对一些相关的技术加以改进，以改善码流、编码质量、延时和算法复杂度之间的关系，达到最优化设置。
3. `H.265` 是一种更为高效的编码标准，能够在同等画质效果下将内容的体积压缩得更小，传输时更快更省带宽
4. `I帧`:(关键帧)保留一副完整的画面，解码时只需要本帧数据就可以完成（因为包含完整画面）
5. `P帧`:(差别帧)保留这一帧跟之前帧的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（P帧没有完整画面数据，只有与前一帧的画面差别的数据）
6. `B帧`:(双向差别帧)保留的是本帧与前后帧的差别，解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码时CPU会比较累
7. `帧内（Intraframe）压缩`:当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息,帧内一般采用有损压缩算法
8. `帧间（Interframe）压缩`:时间压缩（Temporal compression），它通过比较时间轴上不同帧之间的数据进行压缩。帧间压缩一般是无损的
9. `muxing（合成）`：将视频流、音频流甚至是字幕流封装到一个文件中(容器格式（FLV，TS）)，作为一个信号进行传输。

### 2.3 音频编码技术

`AAC`，`mp3`：这些属于音频编码技术,压缩音频用

### 2.4码率控制

`多码率`:观众所处的网络情况是非常复杂的，有可能是WiFi，有可能4G、3G、甚至2G，那么怎么满足多方需求呢？多搞几条线路，根据当前网络环境自定义码率。
        列如：常常看见视频播放软件中的1024，720，高清，标清，流畅等，指的就是各种码率。
### 2.5 视频封装格式

`TS`: 一种流媒体封装格式，流媒体封装有一个好处，就是不需要加载索引再播放，大大减少了首次载入的延迟，如果片子比较长，mp4文件的索引相当大，影响用户体验
        `TS优势`:这是因为两个TS片段可以无缝拼接，播放器能连续播放

`FLV`: 一种流媒体封装格式,由于它形成的文件极小、加载速度极快，使得网络观看视频文件成为可能,因此FLV格式成为了当今主流视频格式

## 3、ijkplayer